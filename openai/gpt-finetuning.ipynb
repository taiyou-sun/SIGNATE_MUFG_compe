{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI APIã‚­ãƒ¼ã®è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿å–ã‚‹ï¼‰\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONLãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¾ã—ãŸ: train_formatted.jsonl\n",
      "FileObject(id='file-7CyUaw4esO9MKZcIwtjSDGiz', bytes=5141790, created_at=1723673190, filename='train_formatted.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "FileObject(id='file-axLuUT37rcFoFFO6OfMmvLdK', bytes=319241, created_at=1723673190, filename='validation_formatted.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "FineTuningJob(id='ftjob-ZNVFc0ya6uDw5MtIECHb6XQT', created_at=1723673193, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-rso2SGee1kCpNT9F9W8Ek6ak', result_files=[], seed=1491910185, status='validating_files', trained_tokens=None, training_file='file-7CyUaw4esO9MKZcIwtjSDGiz', validation_file='file-axLuUT37rcFoFFO6OfMmvLdK', estimated_finish=None, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_data(df):\n",
    "    \"\"\"\n",
    "    ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã€ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ã€‚\n",
    "    \n",
    "    :param df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "    :param is_training: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å ´åˆTrue\n",
    "    :return: ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        review = row['review']\n",
    "        reply = row['replyContent']\n",
    "        thumbsUpCount = row['thumbsUpCount']\n",
    "        reviewCreatedVersion = row['reviewCreatedVersion']\n",
    "        timeToReply = row['timeToReply']\n",
    "        processed_data.append(f\"Review: {review}\\nthumbsUpCount: {thumbsUpCount}, reviewCreatedVersion: {reviewCreatedVersion}\\nReply: {reply}\\ntimeToReply: {timeToReply}\")\n",
    "    return processed_data\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "train_df = pd.read_csv('train_sampled.csv')\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "reviews = process_data(train_df)\n",
    "\n",
    "scores = train_df[\"score\"]\n",
    "\n",
    "save_file = \"train_formatted.jsonl\"\n",
    "\n",
    "import json\n",
    "\n",
    "# JSONLãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€\n",
    "with open(save_file, 'w', encoding='utf-8') as f:\n",
    "    for review, score in zip(reviews, scores):\n",
    "        data = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an AI assistant specialized in analyzing detailed app reviews for BANKApp and predicting review scores. Given a review that includes the review text, thumbs up count, app version, official reply , and reply time, you will predict the likely star rating (0-4 stars) the reviewer would give. \"\n",
    "                    #Consider all provided information in your analysis. Factors to consider include the sentiment of the review, the app version, the presence and quality of an official reply, and the response time. Provide only the numerical score without any explanation or additional commentary.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": review\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": str(score)\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "        f.write('\\n')  # å„JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å¾Œã«æ”¹è¡Œã‚’è¿½åŠ \n",
    "\n",
    "print(f\"JSONLãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¾ã—ãŸ: {save_file}\")\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "train = client.files.create(\n",
    "  file=open(\"train_formatted.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "print(train)\n",
    "\n",
    "valid = client.files.create(\n",
    "  file=open(\"validation_formatted.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "print(valid)\n",
    "\n",
    "ft = client.fine_tuning.jobs.create(\n",
    "  training_file=train.id, \n",
    "  validation_file=valid.id,\n",
    "  model=\"gpt-3.5-turbo-0125\"\n",
    ")\n",
    "print(ft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create At: 2024-08-15 07:06:33\n",
      "FineTune ID: ftjob-ZNVFc0ya6uDw5MtIECHb6XQT\n",
      "Model: None\n",
      "Status: validating_files\n",
      "\n",
      "Create At: 2024-08-14 22:59:59\n",
      "FineTune ID: ftjob-dnO21QruCRFc0CugVWczAS56\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::9w9nRfyc\n",
      "Status: succeeded\n",
      "\n",
      "Create At: 2024-08-14 21:31:33\n",
      "FineTune ID: ftjob-NfmBc7D9dm0xIh2Mw7S7ylGC\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::9w87YvQj\n",
      "Status: succeeded\n",
      "\n",
      "Create At: 2024-08-14 19:43:36\n",
      "FineTune ID: ftjob-gh5BqMGuNfhVNscOrCaJDCN5\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::9w6Mw4uL\n",
      "Status: succeeded\n",
      "\n",
      "Create At: 2024-08-14 19:14:42\n",
      "FineTune ID: ftjob-HCZOzt6vxxgcNTEoUepUhKTy\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::9w5vS9JD\n",
      "Status: succeeded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "ft_jobs = client.fine_tuning.jobs.list()\n",
    "for ft_job in ft_jobs:\n",
    "  id = ft_job.id\n",
    "\n",
    "  timestamp     = ft_job.created_at\n",
    "  datetime      = datetime.fromtimestamp(timestamp)\n",
    "  \n",
    "  # Retrieve the state of a fine-tune\n",
    "  state = client.fine_tuning.jobs.retrieve(id).status\n",
    "  model = client.fine_tuning.jobs.retrieve(id).fine_tuned_model\n",
    "\n",
    "  if state == 'cancelled':\n",
    "    continue\n",
    "\n",
    "  print(f'Create At: {datetime}')\n",
    "  print(f'FineTune ID: {id}')\n",
    "  print(f'Model: {model}')\n",
    "  print(f'Status: {state}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: curl: command not found\n"
     ]
    }
   ],
   "source": [
    "!curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-NfmBc7D9dm0xIh2Mw7S7ylGC/checkpoints -H \"Authorization: Bearer $OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='4', refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::9w5vS9JD\", #fine tuningã—ãŸãƒ¢ãƒ‡ãƒ«ã®ID\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI assistant specialized in analyzing detailed app reviews for BANKApp and predicting review scores. Given a review that includes the review text, thumbs up count, app version, official reply (if any), and reply time, you will predict the likely star rating (0-4 stars) the reviewer would give. Consider all provided information in your analysis. Factors to consider include the sentiment of the review, the app version, the presence and quality of an official reply, and the response time. Provide only the numerical score without any explanation or additional commentary.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Review: niceay ðŸ‘Œ\\nthumbsUpCount: 0, reviewCreatedVersion: 33.0\\nReply: Hello, BANK friends. We appreciate your feedback; keep boosting your banking transactions with the BANKApp app. Thanks, Rida.\\ntimeToReply: 0 days 01::00\"},\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-NfmBc7D9dm0xIh2Mw7S7ylGC', created_at=1723638693, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::9w87YvQj', finished_at=1723641266, hyperparameters=Hyperparameters(n_epochs=3, batch_size=2, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-rso2SGee1kCpNT9F9W8Ek6ak', result_files=['file-sEIwuSQrz99DMdwnBd5fDaPY'], seed=1395981742, status='succeeded', trained_tokens=766221, training_file='file-A5lW8c0hP9CHVtgscHg8vP3V', validation_file='file-5MYdnVgcEcyZaOJ7WeexVAEo', estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-NfmBc7D9dm0xIh2Mw7S7ylGC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-4o-mini-2024-07-18:personal::9w9nR2PO:ckpt-step-1002\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI assistant specialized in analyzing detailed app reviews for BANKApp and predicting review scores. Given a review that includes the review text, thumbs up count, app version, official reply , and reply time, you will predict the likely star rating (0-4 stars) the reviewer would give. \"}, \n",
    "    {\"role\": \"user\", \"content\": \"Review: I am unable to withdraw cash through the app because when I first opened the account, I was not provided with an ATM card. Despite the app being updated and the network being stable, the problem persists. What should I do?\\nthumbsUpCount: 0, reviewCreatedVersion: 33.0\\nReply: Hello BANK Friend, kindly provide all necessary details through Whatsapp 0812 12 14017 or email BANKApp@BANK.co.id for review and follow-up. If everything is in order, we hope to receive 5 stars from your friend. Thanks~Diva\\ntimeToReply: 0 days 03:11:00\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-ZNVFc0ya6uDw5MtIECHb6XQT', created_at=1723673193, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=14, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-rso2SGee1kCpNT9F9W8Ek6ak', result_files=[], seed=1491910185, status='cancelled', trained_tokens=None, training_file='file-7CyUaw4esO9MKZcIwtjSDGiz', validation_file='file-axLuUT37rcFoFFO6OfMmvLdK', estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.cancel(\"ftjob-ZNVFc0ya6uDw5MtIECHb6XQT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': \"The model 'ft:gpt-4o-mini-2024-07-18:personal::9w6Mw4uL' does not exist\", 'type': 'invalid_request_error', 'param': 'model', 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Delete a fine-tuned model (must be an owner of the org the model was created in)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mft:gpt-4o-mini-2024-07-18:personal::9w6Mw4uL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_env/lib/python3.10/site-packages/openai/resources/models.py:116\u001b[0m, in \u001b[0;36mModels.delete\u001b[0;34m(self, model, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `model` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/models/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModelDeleted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_env/lib/python3.10/site-packages/openai/_base_client.py:1295\u001b[0m, in \u001b[0;36mSyncAPIClient.delete\u001b[0;34m(self, path, cast_to, body, options)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete\u001b[39m(\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1288\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     options: RequestOptions \u001b[38;5;241m=\u001b[39m {},\n\u001b[1;32m   1293\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT:\n\u001b[1;32m   1294\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_env/lib/python3.10/site-packages/openai/_base_client.py:936\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_env/lib/python3.10/site-packages/openai/_base_client.py:1040\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1039\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1043\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1044\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[1;32m   1049\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': \"The model 'ft:gpt-4o-mini-2024-07-18:personal::9w6Mw4uL' does not exist\", 'type': 'invalid_request_error', 'param': 'model', 'code': 'model_not_found'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
    "client.models.delete(\"ft:gpt-4o-mini-2024-07-18:personal::9w6Mw4uL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
